{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0663be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, Normalize\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import gudhi as gd\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.set_printoptions(precision=2, sci_mode=False, linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af19c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistence_diagram(image):\n",
    "\n",
    "    h, w = image.shape\n",
    "    img_flat = image.flatten()\n",
    "\n",
    "    ccomplex = gd.CubicalComplex(\n",
    "        dimensions = (h, w), \n",
    "        top_dimensional_cells=img_flat\n",
    "    )\n",
    "    \n",
    "    # get pairs of critical simplices\n",
    "    ccomplex.compute_persistence()\n",
    "    critical_pairs = ccomplex.cofaces_of_persistence_pairs()\n",
    "\n",
    "    # get essential critical pixels (never vanish)\n",
    "    essential_features = critical_pairs[1][0]\n",
    "\n",
    "    # 0-homology image critical pixels\n",
    "    try:\n",
    "        critical_pairs_0 = critical_pairs[0][0]\n",
    "    except:\n",
    "        critical_pairs_0 = np.empty((0, 2))\n",
    "    critical_0_ver_ind = critical_pairs_0 // w\n",
    "    critical_0_hor_ind = critical_pairs_0 % w\n",
    "    critical_pixels_0 = np.stack([critical_0_ver_ind, critical_0_hor_ind], axis=2)\n",
    "\n",
    "    # 0-homology essential pixels (ends with last added pixel)\n",
    "    last_pixel = torch.argmax(image).item()\n",
    "    essential_pixels_0 = np.array([[essential_features[0] // w, essential_features[0] % w], [last_pixel // w, last_pixel % 4]])[np.newaxis, ...]\n",
    "    critical_pixels_0 = np.vstack([critical_pixels_0, essential_pixels_0])\n",
    "\n",
    "    # 0-homology persistance diagram\n",
    "    pd0 = image[critical_pixels_0[:, :, 0].flatten(), critical_pixels_0[:, :, 1].flatten()].reshape((critical_pixels_0.shape[0], 2))\n",
    "\n",
    "    # 1-homology image critical pixels\n",
    "    try:\n",
    "        critical_pairs_1 = critical_pairs[0][1]\n",
    "    except:\n",
    "        critical_pairs_1 = np.empty((0, 2))\n",
    "    critical_1_ver_ind = critical_pairs_1 // w\n",
    "    critical_1_hor_ind = critical_pairs_1 % w\n",
    "    critical_pixels_1 = np.stack([critical_1_ver_ind, critical_1_hor_ind], axis=2)\n",
    "\n",
    "    # 1-homology persistance diagram\n",
    "    pd1 = image[critical_pixels_1[:, :, 0].flatten(), critical_pixels_1[:, :, 1].flatten()].reshape((critical_pixels_1.shape[0], 2))\n",
    "\n",
    "    return pd0, pd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47eb3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagram(image, device, sublevel=True):\n",
    "    # get height and square image\n",
    "    h = int(np.sqrt(image.shape[0]))\n",
    "    image_sq = image.reshape((h,h))\n",
    "\n",
    "    # create complex\n",
    "    cmplx = gd.CubicalComplex(dimensions=(h, h), top_dimensional_cells=(sublevel*image))\n",
    "\n",
    "    # get pairs of critical simplices\n",
    "    cmplx.compute_persistence()\n",
    "    critical_pairs = cmplx.cofaces_of_persistence_pairs()\n",
    "    \n",
    "    # get essential critical pixel\n",
    "    bpx0_essential = critical_pairs[1][0][0] // h, critical_pairs[1][0][0] % h\n",
    "\n",
    "    # get critical pixels corresponding to critical simplices\n",
    "    try:\n",
    "        bpx0 = [critical_pairs[0][0][i][0] for i in range(len(critical_pairs[0][0]))]\n",
    "        dpx0 = [critical_pairs[0][0][i][1] for i in range(len(critical_pairs[0][0]))]\n",
    "    except IndexError:\n",
    "        bpx0 = []\n",
    "        dpx0 = []\n",
    "        \n",
    "    try:\n",
    "        bpx1 = [critical_pairs[0][1][i][0] for i in range(len(critical_pairs[0][1]))]\n",
    "        dpx1 = [critical_pairs[0][1][i][1] for i in range(len(critical_pairs[0][1]))]\n",
    "    except IndexError:\n",
    "        bpx1 = []\n",
    "        dpx1 = []\n",
    "    \n",
    "\n",
    "    flat_image = image_sq.flatten()\n",
    "    pd0_essential = torch.tensor([[image_sq[bpx0_essential], torch.max(image)]])\n",
    "\n",
    "    if (len(bpx0)!=0):\n",
    "        pdb0 = flat_image[bpx0][:, None]\n",
    "        pdd0 = flat_image[dpx0][:, None]\n",
    "        pd0 = torch.Tensor(torch.hstack([pdb0, pdd0]))\n",
    "        pd0 = torch.vstack([pd0, pd0_essential.to(device)])\n",
    "    else:\n",
    "        pd0 = pd0_essential\n",
    "\n",
    "    if (len(bpx1)!=0):\n",
    "        pdb1 = flat_image[bpx1][:, None]\n",
    "        pdd1 = flat_image[dpx1][:, None]\n",
    "        pd1 = torch.Tensor(torch.hstack([pdb1, pdd1]))\n",
    "    else:\n",
    "        pd1 = torch.zeros((1, 2))\n",
    "    \n",
    "    return pd0, pd1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8cc673",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95fb93e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([Resize((14, 14)), ToTensor(), Normalize(0.0, 1.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14650b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "dataloader_train = DataLoader(data_train, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb523f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.04, 0.09, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.34, 0.69, 0.16, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.28, 0.90, 0.49, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.25, 0.91, 0.72, 0.08, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.18, 0.84, 0.86, 0.22, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.04, 0.59, 0.98, 0.47, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.34, 0.94, 0.59, 0.03, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.24, 0.90, 0.73, 0.08, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.15, 0.80, 0.80, 0.15, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.05, 0.65, 0.93, 0.32, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.38, 0.76, 0.26, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.04, 0.09, 0.02, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]]],\n",
       "\n",
       "\n",
       "        [[[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.03, 0.11, 0.12, 0.06, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.05, 0.25, 0.46, 0.60, 0.70, 0.35, 0.01, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.01, 0.16, 0.47, 0.53, 0.46, 0.54, 0.53, 0.11, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.20, 0.59, 0.38, 0.45, 0.56, 0.35, 0.09, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.02, 0.47, 0.39, 0.02, 0.09, 0.07, 0.01, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.01, 0.40, 0.54, 0.08, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.10, 0.54, 0.49, 0.12, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.00, 0.00, 0.08, 0.39, 0.55, 0.11, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.03, 0.01, 0.00, 0.13, 0.63, 0.24, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.01, 0.30, 0.20, 0.16, 0.52, 0.50, 0.07, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.20, 0.52, 0.56, 0.38, 0.07, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "          [0.00, 0.00, 0.00, 0.01, 0.07, 0.09, 0.02, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(dataloader_train))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82153dde",
   "metadata": {},
   "source": [
    "### Differentiability of persistent homology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471fc848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Img2PD(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 3))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X_conv = self.conv(X)\n",
    "        \n",
    "        peristence_diagrams = []\n",
    "        for i, x_conv in enumerate(X_conv):\n",
    "            pd = persistence_diagram(x_conv[0])\n",
    "            peristence_diagrams.append(pd)\n",
    "        \n",
    "        return peristence_diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f9d5cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[-0.52, -0.51],\n",
       "          [-0.54, -0.25]], grad_fn=<ReshapeAliasBackward0>),\n",
       "  tensor([[ 0.02,  0.08],\n",
       "          [ 0.02,  0.09],\n",
       "          [-0.05,  0.11]], grad_fn=<ReshapeAliasBackward0>)),\n",
       " (tensor([[-0.39, -0.38],\n",
       "          [-0.30, -0.30],\n",
       "          [-0.29, -0.27],\n",
       "          [-0.43, -0.26],\n",
       "          [-0.34, -0.25],\n",
       "          [-0.44, -0.03]], grad_fn=<ReshapeAliasBackward0>),\n",
       "  tensor([[-0.25, -0.25],\n",
       "          [-0.25, -0.25],\n",
       "          [-0.17, -0.15],\n",
       "          [-0.10, -0.10],\n",
       "          [-0.19, -0.09],\n",
       "          [-0.13, -0.07],\n",
       "          [-0.18, -0.06],\n",
       "          [-0.12, -0.04],\n",
       "          [-0.22, -0.03]], grad_fn=<ReshapeAliasBackward0>))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Img2PD()\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4c1ab",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "- any differentiable image transform (convolution, directional filter, etc.),\n",
    "- sublevel filtration persistent homology layer, mapping an image to a set of persistent diagrams of dimensions 0 and 1,\n",
    "- any layer taking a set as an input -- DeepSets, Transformer, etc.,\n",
    "- an aggregation layer, aggregating a transformed persistent diagrams into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f1da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDiagram(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(ConvDiagram, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, x):\n",
    "        diagrams = []\n",
    "        for i in range(x.shape[0]):\n",
    "            res = diagram(x[i].flatten(), self.device)\n",
    "            for j in range(len(res)):\n",
    "                diagrams.append(torch.concatenate([res[j], torch.Tensor([[j, i] for _ in range(res[j].shape[0])]).to(self.device)], axis=1))\n",
    "        diagrams = torch.concatenate(diagrams)\n",
    "        return diagrams\n",
    "\n",
    "\n",
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out, seq_size=1024, nhead=2, num_layers=2, dim_feedforward=16):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.embeddings = nn.Linear(n_in, n_hidden)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=n_hidden, nhead=nhead, dim_feedforward=dim_feedforward, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer=self.encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(seq_size, n_out)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.embeddings(X)\n",
    "        X = self.transformer(X)\n",
    "        X = X.mean(dim=-1)\n",
    "        X = self.classifier(X)\n",
    "        X = X.softmax(dim=-1)\n",
    "        return X\n",
    "\n",
    "\n",
    "class TopologicalConvTransformer(nn.Module):\n",
    "    def __init__(self, n_in, n_conv, max_sequence, n_diag, n_hidden, n_out, nhead=2, num_layers=2, dim_feedforward=16, device='cuda'):\n",
    "        super(TopologicalConvTransformer, self).__init__()\n",
    "        \n",
    "        self.max_sequence = max_sequence\n",
    "        self.conv = nn.Conv2d(n_in, n_conv, 3)\n",
    "        self.diagram = ConvDiagram(device)\n",
    "        self.transformer = Transformer(n_diag, n_hidden, n_out, max_sequence, nhead, num_layers, dim_feedforward)\n",
    "\n",
    "    def forward(self, xs):\n",
    "        result = []\n",
    "        for i in range(xs.shape[0]):\n",
    "            x = xs[i][None, :, :] / 256\n",
    "            x = self.conv(x)\n",
    "            x = self.diagram(x)\n",
    "            if x.shape[0] > self.max_sequence:\n",
    "                x = x[:self.max_sequence]\n",
    "            x = F.pad(x, (0, 0, 0, self.max_sequence - x.shape[0]), \"constant\", 0)\n",
    "            x = self.transformer(x)\n",
    "            result.append(x[None, :])\n",
    "        result = torch.concatenate(result, axis=0)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be829752",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"n_in\": 1,\n",
    " \"n_conv\": 1,\n",
    " \"max_sequence\": 64,\n",
    " \"n_diag\": 4,\n",
    " \"n_hidden\": 32, \"n_out\": 10, \"nhead\": 2, \"num_layers\": 2, \"dim_feedforward\": 16, \"device\": \"cpu\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f96ce566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.09, 0.11, 0.11, 0.11, 0.10, 0.09, 0.09, 0.10, 0.10, 0.10], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TopologicalConvTransformer(**kwargs)\n",
    "model(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7babbc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 Loss   Acc   \n",
      "  0 2.3009 0.1138\n",
      "  1 2.2643 0.1863\n",
      "  2 2.2337 0.1730\n",
      "  3 2.2264 0.2261\n",
      "  4 2.2210 0.2285\n",
      "  5 2.2141 0.2314\n",
      "  6 2.2086 0.2458\n",
      "  7 2.2047 0.2532\n",
      "  8 2.1976 0.2749\n",
      "  9 2.1915 0.2750\n",
      " 10 2.1850 0.2817\n",
      " 11 2.1833 0.2799\n",
      " 12 2.1783 0.2823\n",
      " 13 2.1746 0.2770\n",
      " 14 2.1714 0.2838\n",
      " 15 2.1698 0.2761\n",
      " 16 2.1684 0.2550\n",
      " 17 2.1675 0.2792\n",
      " 18 2.1654 0.2832\n",
      " 19 2.1659 0.2836\n",
      "\n",
      "CPU times: user 9min 48s, sys: 2min 45s, total: 12min 34s\n",
      "Wall time: 10min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_repeats = 1\n",
    "n_epochs = 20\n",
    "batch_size = 100\n",
    "lr = 0.001\n",
    "\n",
    "history = np.zeros((n_repeats, n_epochs, 3))\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "for repeat_idx in range(n_repeats):\n",
    "    \n",
    "    # data init\n",
    "    dataloader_train = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # model init\n",
    "    model = TopologicalConvTransformer(**kwargs)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    print(\"{:3} {:6} {:6}\".format(repeat_idx, \"Loss\", \"Acc\"))\n",
    "    \n",
    "    for epoch_idx in range(n_epochs):\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        \n",
    "        loss_epoch = []\n",
    "        for batch in dataloader_train:\n",
    "            loss_batch = criterion(model(batch[0]), batch[1])\n",
    "            loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_epoch.append(loss_batch.detach())\n",
    "        \n",
    "        loss_epoch_mean = np.array(loss_epoch).mean()\n",
    "        history[repeat_idx,epoch_idx,0] = loss_epoch_mean\n",
    "        \n",
    "        # test\n",
    "        model.eval()\n",
    "        \n",
    "        correct = 0\n",
    "        for batch in dataloader_train:\n",
    "            y_hat = model(batch[0]).argmax(dim=1)\n",
    "            correct += int((y_hat == batch[1]).sum())\n",
    "        accuracy_train = correct / len(dataloader_train.dataset)\n",
    "        history[repeat_idx,epoch_idx,1] = accuracy_train\n",
    "        \n",
    "        print(\"{:3} {:.4f} {:.4f}\".format(epoch_idx, loss_epoch_mean, accuracy_train))\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe72cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b746b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
